{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring outbreaks in India using geopandas\n",
    "\n",
    "## Outline\n",
    "\n",
    "In this notebook, the outbreaks of different diseases in India will be explored. Outbreak data by district is merged with the geospatial information of each district to map outbreaks. Furthermore the time evolution of outbreaks can also be mapped.\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "Disease outbreak data for India was downloaded from the [Integrated Disease Surveillance Program](https://idsp.nic.in/) in the form of weekly reports in .pdf format. The dataset spans 2009 to present day and is extracted from the .pdf files using `idsp_parser.py`. It is then merged with district data from [Global Administrative Area Maps](https://gadm.org) to form a _master_ geopandas dataframe which has all the information for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from datetime import datetime\n",
    "import shapely as sh\n",
    "%matplotlib notebook\n",
    "\n",
    "df = pd.read_csv(\"/users/rsg/anla/podcast/country_disease_outbreaks/india/idsp_reporting/IDSP_data.csv\")\n",
    "df_1 = df.copy()\n",
    "IND_2 = gpd.read_file(\"/data/datasets/Projects/PODCAST/country_district_shape_files/INDIA/gadm36_IND_2.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID_code</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>disease</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>start_date</th>\n",
       "      <th>report_date</th>\n",
       "      <th>status</th>\n",
       "      <th>comments</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Dadra and Nagar Haveli</td>\n",
       "      <td>Dadra and Nagar Haveli</td>\n",
       "      <td>?</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>[]</td>\n",
       "      <td>?</td>\n",
       "      <td>5 7 12 1 2 1  1 144 71 40 36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Dadra and Nagar Haveli</td>\n",
       "      <td>Dadra and Nagar Haveli</td>\n",
       "      <td>?</td>\n",
       "      <td>34</td>\n",
       "      <td>17</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>[]</td>\n",
       "      <td>?</td>\n",
       "      <td>34 17 15 17 10  7 5 3 2 2 1 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>NCT of Delhi</td>\n",
       "      <td>West</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>[]</td>\n",
       "      <td>?</td>\n",
       "      <td>3 2 2 1 1 1  1 0 20 40 60  80 100 120 140 160 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Prakasam</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>27-06-09</td>\n",
       "      <td>30-06-09</td>\n",
       "      <td>['Under Control']</td>\n",
       "      <td>?</td>\n",
       "      <td>taken Nellore i. Acute Diarrhoeal Disease  43 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Chhota Udaipur</td>\n",
       "      <td>Food Poisoning</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>25-06-09</td>\n",
       "      <td>27-06-09</td>\n",
       "      <td>['Under Control']</td>\n",
       "      <td>?</td>\n",
       "      <td>Pradesh Prakasam ii. Acute Diarrhoeal Disease ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17371</th>\n",
       "      <td>17371</td>\n",
       "      <td>['TN/RMN/2019/06/0161']</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>Ramanathapuram</td>\n",
       "      <td>Chikungunya</td>\n",
       "      <td>21</td>\n",
       "      <td>00</td>\n",
       "      <td>05-02-19</td>\n",
       "      <td>11-02-19</td>\n",
       "      <td>['Under Control']</td>\n",
       "      <td>?</td>\n",
       "      <td>TN/RMN/2019/06/0161 Tamil Nadu Ramanathapura m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17372</th>\n",
       "      <td>17372</td>\n",
       "      <td>['TL/BLY/2019/06/0162']</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Ranga Reddy</td>\n",
       "      <td>Food Poisoning</td>\n",
       "      <td>40</td>\n",
       "      <td>00</td>\n",
       "      <td>04-02-19</td>\n",
       "      <td>06-02-19</td>\n",
       "      <td>['Under Control']</td>\n",
       "      <td>?</td>\n",
       "      <td>TL/BLY/2019/06/0162 Telangana Jayashankar Bhup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17373</th>\n",
       "      <td>17373</td>\n",
       "      <td>['KN/CMN/2019/06/0163']</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Mysore</td>\n",
       "      <td>?</td>\n",
       "      <td>31</td>\n",
       "      <td>00</td>\n",
       "      <td>21-01-19</td>\n",
       "      <td>?</td>\n",
       "      <td>['Under Surveillance']</td>\n",
       "      <td>?</td>\n",
       "      <td>KN/CMN/2019/06/0163 Karnataka Chamarajanagar a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>17374</td>\n",
       "      <td>['KL/WYN/2019/06/0164']</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Wayanad</td>\n",
       "      <td>Food Poisoning</td>\n",
       "      <td>55</td>\n",
       "      <td>00</td>\n",
       "      <td>28-01-19</td>\n",
       "      <td>?</td>\n",
       "      <td>['Under Surveillance']</td>\n",
       "      <td>?</td>\n",
       "      <td>KL/WYN/2019/06/0164 Kerala Wayanad Food Poison...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>17375</td>\n",
       "      <td>['TN/KRR/2019/06/0165']</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>Karur</td>\n",
       "      <td>Leptospirosis</td>\n",
       "      <td>40</td>\n",
       "      <td>00</td>\n",
       "      <td>23-01-19</td>\n",
       "      <td>?</td>\n",
       "      <td>['Under Surveillance']</td>\n",
       "      <td>?</td>\n",
       "      <td>TN/KRR/2019/06/0165 Tamil Nadu Karur Leptospir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17376 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                  ID_code                   state  \\\n",
       "0               0                       []  Dadra and Nagar Haveli   \n",
       "1               1                       []  Dadra and Nagar Haveli   \n",
       "2               2                       []            NCT of Delhi   \n",
       "3               3                       []          Andhra Pradesh   \n",
       "4               4                       []                 Gujarat   \n",
       "...           ...                      ...                     ...   \n",
       "17371       17371  ['TN/RMN/2019/06/0161']              Tamil Nadu   \n",
       "17372       17372  ['TL/BLY/2019/06/0162']               Telangana   \n",
       "17373       17373  ['KN/CMN/2019/06/0163']               Karnataka   \n",
       "17374       17374  ['KL/WYN/2019/06/0164']                  Kerala   \n",
       "17375       17375  ['TN/KRR/2019/06/0165']              Tamil Nadu   \n",
       "\n",
       "                     district         disease cases deaths start_date  \\\n",
       "0      Dadra and Nagar Haveli               ?     7     12          ?   \n",
       "1      Dadra and Nagar Haveli               ?    34     17          ?   \n",
       "2                        West               ?     2      2          ?   \n",
       "3                    Prakasam               ?     ?      ?   27-06-09   \n",
       "4              Chhota Udaipur  Food Poisoning     ?      ?   25-06-09   \n",
       "...                       ...             ...   ...    ...        ...   \n",
       "17371          Ramanathapuram     Chikungunya    21     00   05-02-19   \n",
       "17372             Ranga Reddy  Food Poisoning    40     00   04-02-19   \n",
       "17373                  Mysore               ?    31     00   21-01-19   \n",
       "17374                 Wayanad  Food Poisoning    55     00   28-01-19   \n",
       "17375                   Karur   Leptospirosis    40     00   23-01-19   \n",
       "\n",
       "      report_date                  status comments  \\\n",
       "0               ?                      []        ?   \n",
       "1               ?                      []        ?   \n",
       "2               ?                      []        ?   \n",
       "3        30-06-09       ['Under Control']        ?   \n",
       "4        27-06-09       ['Under Control']        ?   \n",
       "...           ...                     ...      ...   \n",
       "17371    11-02-19       ['Under Control']        ?   \n",
       "17372    06-02-19       ['Under Control']        ?   \n",
       "17373           ?  ['Under Surveillance']        ?   \n",
       "17374           ?  ['Under Surveillance']        ?   \n",
       "17375           ?  ['Under Surveillance']        ?   \n",
       "\n",
       "                                                     raw  \n",
       "0                         5 7 12 1 2 1  1 144 71 40 36    \n",
       "1                       34 17 15 17 10  7 5 3 2 2 1 1 1   \n",
       "2      3 2 2 1 1 1  1 0 20 40 60  80 100 120 140 160 ...  \n",
       "3      taken Nellore i. Acute Diarrhoeal Disease  43 ...  \n",
       "4      Pradesh Prakasam ii. Acute Diarrhoeal Disease ...  \n",
       "...                                                  ...  \n",
       "17371  TN/RMN/2019/06/0161 Tamil Nadu Ramanathapura m...  \n",
       "17372  TL/BLY/2019/06/0162 Telangana Jayashankar Bhup...  \n",
       "17373  KN/CMN/2019/06/0163 Karnataka Chamarajanagar a...  \n",
       "17374  KL/WYN/2019/06/0164 Kerala Wayanad Food Poison...  \n",
       "17375  TN/KRR/2019/06/0165 Tamil Nadu Karur Leptospir...  \n",
       "\n",
       "[17376 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up the data\n",
    "\n",
    "The IDSP_parser.py program returns a .csv file of outbreaks. However, further processing is required to clean the dataset. These steps are:\n",
    "\n",
    "* Consolidate duplicated reporting\n",
    "* Convert string columns to numeric, datetime and other datatypes\n",
    "* Merging outbreak DataFrame with GeoDataFrame to connect the outbreak data with geospatial information\n",
    "\n",
    "After these basic steps are complete, then the data can be queried and plotted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting string to units\n",
    "\n",
    "start date columns goes to datetime object\n",
    "\n",
    "cases, deaths columns go to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[['start_date','report_date']] = df[['start_date','report_date']].apply(lambda x: pd.to_datetime(x, dayfirst=True, errors='coerce'))\n",
    "df_1[['cases','deaths']] = df[['cases','deaths']].apply(lambda x : pd.to_numeric(x, errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv('idsp_outbreaks_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates\n",
    "\n",
    "If an outbreak continues to the next week. A follow up report is common. It will have the same location, disease and date, with revised figures for the total number of cases (I believe). Also post 2016 it will share the ID code of the original report of that outbreak.\n",
    "\n",
    "The solution is to use:\n",
    "\n",
    "```\n",
    "DataFrame.Duplicated()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.sort_values(by='start_date')#.sort_values(by='report_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[df_1.duplicated(subset=['state','district','disease','start_date'], keep='last') == True].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__There appears to be 664 follow up report duplications.__ This means that we should probably throw away these records. Explore these records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_duplicates = df_1[(df_1.disease != '?') & \\\n",
    "     (df_1.duplicated(subset=['state','district','disease','start_date'],\n",
    "                      keep=False) == True)].sort_values(by=['start_date','cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_duplicates[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore these datasets. _outbreaks_ has text information regarding outbreaks; when, where, what, how many and current status. There is also a comments field which contains potentially useful but unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the rows with the same ID_code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outbreaks[outbreaks.duplicated('ID_code') == False].set_index(['state','district']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks[outbreaks.duplicated('cases',keep=False) == False]#.groupby(['state','district']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ISSUE:__ The post 2016 records with codified ID_codes are easy to find followup reports for. However the pre 2016 records reuse the serial numbers each week resulting in a 100s of repeats. This could be solved only recording propper ID codes in the ID code column. Also a more sophisticated matching routine could be used to find same day same disease same location and use that... We could also retrospectively generate ID codes for the pre 2016 records, which could be neat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any value which was not found when creating the dataframe has been replaced with a ?. One way to handle this is to drop all records that contain? Another is to go through and format the columnns correctly. The latter is better as it carries more information.\n",
    "\n",
    "We would like to\n",
    "\n",
    "* Make the cases and deaths field to integer\n",
    "* Make the dates into datatime object\n",
    "\n",
    "Using `apply` apply the `.to_numeric()` method along the case and death columns. Errors are coerced, meaning failure results in a NAN value which is then dropped. `lambda` function is used here in order to set the errors='coerce'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outbreaks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4a312b349ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutbreaks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cases'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'deaths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutbreaks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cases'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'deaths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'outbreaks' is not defined"
     ]
    }
   ],
   "source": [
    "outbreaks[['cases','deaths']] = outbreaks[['cases','deaths']].apply(lambda x : pd.to_numeric(x, errors='coerce'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarly `apply` `to_datetime` to convert the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks[['start_date','report_date']] = outbreaks[['start_date','report_date']].apply(lambda x: pd.to_datetime(x, errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks.start_date[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the geospatial element\n",
    "\n",
    "There are a few ways we can connect the outbreak data with the region map of India."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IND_3 is a geopandas, geodataframe which has shape file geometry for the administrative regions of India. As per the following convention,\n",
    "\n",
    " * NAME_1 is the state\n",
    " * NAME_2 is the district\n",
    " * NAME_3 is the city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the data columns in the IND_2 geodataframe are not populated and therefore not helpful.\n",
    "\n",
    "## Quick plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two data frames can be merged using the dataframe method `.merge()`. By merging the two, we can attach the shape file for the district to the outbreaks in that district.\n",
    "\n",
    "In this case we are interested in the _state_ and _district_ columns because that is the highest resolution the outbreak dataframe has. State must be included because some districts share the same name but are located in different states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this _NAME\\_1_ and _NAME\\_2_ are renamded to _state_ and _district_ for compatibility with the outbreak dataframe. Next the multiple level 3 (settlements) data is removed. The dissolve method deals with multiple rows with the same district, keeping the geometry of the first row with a given district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GeoDataFrame' object has no attribute 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-69ef75abf9ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdistrict_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIND_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NAME_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NAME_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'NAME_1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NAME_2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'district'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0;34m.\u001b[0m\u001b[0mdissolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'district'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maggfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geospatial/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeoDataFrame' object has no attribute 'df'"
     ]
    }
   ],
   "source": [
    "district_locations = IND_2[['NAME_1','NAME_2','geometry']]\\\n",
    "                    .rename(columns={'NAME_1':'state','NAME_2':'district'})\\\n",
    "                    .dissolve(by=['state','district'],aggfunc='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_2[IND_2.NAME_1 == 'Kerala'].set_index('NAME_2').loc[['Alappuzha','Ernakulam','Kottayam']][['geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This geodataframe contains the unique names and geometry for each district in India. Now it must be merged with the outbreak data along the state and district columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a random district and label it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the districts themselves we can use `gpd.plotting.plot_dataframe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# choose a district at random\n",
    "district = random.choice(district_locations.index)\n",
    "\n",
    "gpd.plotting.plot_dataframe(district_locations,\n",
    "                            ax=ax,\n",
    "                           )\n",
    "gpd.plotting.plot_polygon_collection(ax, district_locations.loc[[district],'geometry'],\n",
    "                                     color='red'\n",
    "                                    )\n",
    "\n",
    "# district_locations.loc[[district]].centroid\n",
    "plt.annotate(s=district, xy=(district_locations.loc[[district]].centroid.x,\n",
    "                             district_locations.loc[[district]].centroid.y\n",
    "                            )\n",
    "            )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge outbreaks with geospatial data on state and district columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = district_locations.merge(df_1,on=['state','district'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'master' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-30f79bec3224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'master' is not defined"
     ]
    }
   ],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master[['state','district','disease','cases','geometry']].to_file('IND_outbreaks.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_case_sum = district_locations.merge(master[(master.disease ==  'Cholera')].groupby(['state','district'])['cases'].sum(),\n",
    "                         left_index=True,\n",
    "                         right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_case_sum['log_cases'] = cholera_case_sum['cases'].apply(sp.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_case_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm, SymLogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_case_sum[cholera_case_sum.cases > 0].plot(figsize=(15,15), cmap='Reds', column='log_cases', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save to file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_case_sum[cholera_case_sum.cases == cholera_case_sum.cases.max()].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_case_sum['region'] = cholera_case_sum.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_case_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_case_sum.to_file(\"cholera_case_sum.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination of data sets to map outbreaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Cholera outbreaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the total cholera outbreaks. To do this we select the outbreaks that are cholera. Then take only the district and cases field before merging with the district locations. Now we have a composite dataframe that can make "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(outbreaks.disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_locations.merge(\n",
    "    outbreaks[outbreaks['disease'] == 'Cholera'],\n",
    "    on=['state','district']\n",
    ").to_file('./IDSP_cholera_outbreaks_india_2009_to_2016_geopandas.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gpd.read_file('./IDSP_cholera_outbreaks_india_2009_to_2016_geopandas.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets figure out the total number of cholera cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks[outbreaks.disease == 'Cholera'].cases.dropna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The district locations are ready to be merged with the outbreak data. In this case we just need the number of cholera cases so we select those before merging. That gives a consise geodataframe. Note that the geodataframe should be the one calling the merge() method, otherwise the result will be a normal dataframe, and loose its geo prefix and special abilities. This can be rectified it is just not quite so pleasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite = district_locations.merge(\n",
    "    outbreaks[outbreaks['disease'] == 'Acute Diarrheal Disease'][['state','district','cases']],\n",
    "    on=['state','district']\n",
    ")\n",
    "print(type(composite))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop nan values and aggregate using .dissolve(). This gives us a single row for each district that contains the geometry and number of cases of cholera only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_district_cases = composite.dropna().dissolve(by=['state','district'],aggfunc='sum')\n",
    "print(type(cholera_district_cases))\n",
    "print(cholera_district_cases.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5),dpi=150)\n",
    "\n",
    "IND_2.plot(ax=ax,\n",
    "           color='white',\n",
    "           edgecolor='black',\n",
    "           alpha=1,\n",
    "           linewidth=0.05,\n",
    "          )\n",
    "\n",
    "cholera_district_cases.plot(column = 'cases',\n",
    "                            cmap='Reds',\n",
    "                            ax=ax,\n",
    "                            legend=True,\n",
    "                           )\n",
    "\n",
    "plt.title('Cholera cases 2009-present')\n",
    "\n",
    "# label the 3 most infected districts\n",
    "for index in cholera_district_cases.nlargest(3,columns='cases').index:\n",
    "    gpd.plotting.plot_point_collection(ax,\n",
    "                                       cholera_district_cases.loc[[index]].centroid,\n",
    "#                                        color='black',\n",
    "                                       marker='+',\n",
    "                                       label=\" \".join(index)+\": \"+str(cholera_district_cases.loc[[index]].cases.sum())\n",
    "                                      )\n",
    "    \n",
    "#     plt.annotate(s= \" \".join(index),\n",
    "#                  xy=(cholera_district_cases.loc[[index]].centroid.x,\n",
    "#                      cholera_district_cases.loc[[index]].centroid.y),\n",
    "#                  horizontalalignment='left',\n",
    "#                  verticalalignment='bottom'\n",
    "#                 )\n",
    "\n",
    "# get the total bounding box\n",
    "x0,y0,x1,y1 = cholera_district_cases.total_bounds\n",
    "\n",
    "# display total cases as an inset\n",
    "plt.text(x0 + 1  * (x1-x0),\n",
    "         y0 + 1  * (y1-y0),\n",
    "         'total cases = '+str(int(cholera_district_cases.cases.sum())),\n",
    "         horizontalalignment='right',\n",
    "        )\n",
    "\n",
    "# plt.legend(loc=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap showing total Cholera cases by district from 2009 - present. The results with later version of the data analysis code seems to produce wildly different results. Which isn't reassuring. A ground truth metric against which the data can be compared would be very useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have some informative data. However it should be noted that this representation shows the total number of outbreaks by district. The districts themselves are not equal and this graphic shows neither the spatial density of cholera nor the infection rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_state_cases = cholera_district_cases.dissolve(by='state',aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cholera_state_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[(d['x']>2) & (d['y']>7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mah_cholera = outbreaks[(outbreaks['state'] == 'Maharashtra') & (outbreaks.disease == 'Cholera')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mah_cholera[['district','cases','start_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbreaks.loc[8801].raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master[(master['state'] == 'Kerala') & \\\n",
    "       (master['disease'] == ('Cholera' or 'Acute Diarrheal Disease' or 'Food Poisoning'))].to_file('idsp_IVO_kerala_lake.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kerala_lake = gpd.read_file('idsp_IVO_kerala_lake.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(test_kerala_lake.disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp idsp_IVO* /data/datasets/Projects/REVIVAL/disease_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
